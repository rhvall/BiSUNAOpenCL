//
//  main.cpp
//  TestOpenCL
//
//  Created by RHVT on 6/5/19.
//  Copyright © 2019 R. All rights reserved.
//

#define CL_SILENCE_DEPRECATION

#include <stdio.h>
#include <stdlib.h>
#include <vector>
#include <thread>
#include <iostream>
#include <future>
#include "NN/Module.hpp"
#include "NN/CLNetwork.hpp"

// This include pulls in everything you need to develop with OpenCL in OS X.
#include <OpenCL/opencl.h>

// Include the header file generated by Xcode.  This header file contains the
//  kernel block declaration.                                             // 1
#include "SquareFunction.cl.h"

#include "RedToGreenExample.hpp"
#include "BufferTest.hpp"

// Hard-coded number of values to test, for convenience.
#define NUM_VALUES 1024

void accumulator_function2(const std::vector<int> &v, unsigned long long &acm,
                           unsigned int beginIndex, unsigned int endIndex)
{
    acm = 0;
    for (unsigned int i = beginIndex; i < endIndex; ++i)
    {
        acm += v[i];
    }
}

// A utility function that checks that our kernel execution performs the
// requested work over the entire range of data.
static int validate(cl_float* input, cl_float* output)
{
    int i;
    
    for (i = 0; i < NUM_VALUES; i++) {
        // The kernel was supposed to square each value.
        if (output[i] != (input[i] * input[i])) {
            fprintf(stdout, "Error: Element %d did not match expected output.\n", i);
            fprintf(stdout, "       Saw %1.4f, expected %1.4f\n", output[i], input[i] * input[i]);
            fflush(stdout);
            return 0;
        }
    }
    
    return 1;
}

void runThreads() {
    unsigned int c = std::thread::hardware_concurrency();
    std::cout << " number of cores: " << c << std::endl;;
    
    {
        std::vector<int> v = {1,2,3,4,5,6,7,8,9,10};
        
        unsigned long long acm1 = 0;
        unsigned long long acm2 = 0;
        std::thread t1(accumulator_function2, std::ref(v), std::ref(acm1), 0, v.size() / 2);
        std::thread t2(accumulator_function2, std::ref(v), std::ref(acm2), v.size() / 2, v.size());
        t1.join();
        t2.join();
        
        std::cout << "acm1: " << acm1 << std::endl;
        std::cout << "acm2: " << acm2 << std::endl;
        std::cout << "acm1 + acm2: " << acm1 + acm2 << std::endl;
    }
    
    {
        std::vector<int> v = {1,2,3,4,5,6,7,8,9,10};
        auto f1 = [](std::vector<int> &v,
                     unsigned int left, unsigned int right) {
            unsigned long long acm = 0;
            for (unsigned int i = left; i < right; ++i)
            {
                acm += v[i];
            }
            
            return acm;
        };
        
        auto t1 = std::async(f1, std::ref(v),
                             0, v.size() / 2);
        auto t2 = std::async(f1, std::ref(v),
                             v.size() / 2, v.size());
        
        //You can do other things here!
        unsigned long long acm1 = t1.get();
        unsigned long long acm2 = t2.get();
        
        std::cout << "acm1: " << acm1 << std::endl;
        std::cout << "acm2: " << acm2 << std::endl;
        std::cout << "acm1 + acm2: " << acm1 + acm2 << std::endl;
    }
}

static void print_device_info(cl_device_id device)
{
    char name[128];
    char vendor[128];
    clGetDeviceInfo(device, CL_DEVICE_NAME, 128, name, NULL);
    clGetDeviceInfo(device, CL_DEVICE_VENDOR, 128, vendor, NULL);
    fprintf(stdout, "%s : %s\n", vendor, name);
}

// Demonstrates how to get the global OpenCL context, and how to ask that
// context about the devices it contains.  It also shows how
// to create a dispatch queue by asking for a device type (CPU or GPU) and
// by specifying the queue's OpenCL device directly.

static void hello_world_sample1 ()
{
    int i;
    
    // Ask for the global OpenCL context:
    // Note: If you will not be enqueing to a specific device, you do not need
    // to retrieve the context.
    
    cl_context context = gcl_get_context();
    
    // Query this context to see what kinds of devices are available.
    
    size_t length;
    cl_device_id devices[8];
    clGetContextInfo(context, CL_CONTEXT_DEVICES, sizeof(devices), devices, &length);
    
    // Walk over these devices, printing out some basic information.  You could
    // query any of the information available about the device here.
    
    fprintf(stdout, "The following devices are available for use:\n");
    int num_devices = (int)(length / sizeof(cl_device_id));
    for (i = 0; i < num_devices; i++) {
        print_device_info(devices[i]);
    }
    
    // To do any work, you need to create a dispatch queue associated
    // with some OpenCL device.  You can either let the system give you
    // a GPU—perhaps the only GPU—or the CPU device.  Or, you can
    // create a dispatch queue with a cl_device_id you specify.  This
    // device id comes from the OpenCL context, as above.  Below are three
    // examples.
    
    // 1. Ask for a GPU-based dispatch queue; notice that here we do not provide
    // a device id.  Instead, we let the system tell us the most capable GPU.
    
    dispatch_queue_t gpu_queue =
    gcl_create_dispatch_queue(CL_DEVICE_TYPE_GPU, NULL);
    
    // Get the device from the queue, so we can ask OpenCL questions about it.
    // Note that we check to make sure there WAS an OpenCL-capable GPU in the
    // system by checking against a NULL return value.
    
    if (gpu_queue != NULL) {
        
        cl_device_id gpu_device =
        gcl_get_device_id_with_dispatch_queue(gpu_queue);
        fprintf(stdout, "\nAsking for CL_DEVICE_TYPE_GPU gives us:\n");
        print_device_info(gpu_device);
        
    } else {
        fprintf(stdout, "\nYour system does not contain an OpenCL-compatible "
                "GPU\n.");
    }
    
    // 2. Try the same thing for CL_DEVICE_TYPE_CPU.  All Mac
    // systems have a CPU OpenCL device, so you don't have to
    // check for NULL, as you have to do in the case of a GPU.
    
    dispatch_queue_t cpu_queue =
    gcl_create_dispatch_queue(CL_DEVICE_TYPE_CPU, NULL);
    cl_device_id cpu_device = gcl_get_device_id_with_dispatch_queue(cpu_queue);
    fprintf(stdout, "\nAsking for CL_DEVICE_TYPE_CPU gives us:\n");
    print_device_info(cpu_device);
    
    // 3. Or perhaps you are in a situation where you want a specific device
    // from the list of devices you found on the context.
    // Notice the difference here:
    // Pass CL_DEVICE_TYPE_USE_ID and a device_id. This example just uses the
    // first device on the context from above, whatever that might be.
    
    dispatch_queue_t custom_queue =
    gcl_create_dispatch_queue(CL_DEVICE_TYPE_USE_ID, devices[0]);
    cl_device_id custom_device =
    gcl_get_device_id_with_dispatch_queue(custom_queue);
    fprintf(stdout,
            "\nAsking for CL_DEVICE_TYPE_USE_ID and our own device gives us:\n");
    print_device_info(custom_device);
    
    // Now you can use any of these 3 dispatch queues to run some kernels.
    // Run your kernels here.
    
    // Use the GCD API to free your queues.
    
    dispatch_release(custom_queue);
    dispatch_release(cpu_queue);
    
    if (gpu_queue != NULL) dispatch_release(gpu_queue);
}

// This listing shows how to obtain workgroup info –
// useful for obtaining peak performance—from the kernel block.

static void hello_world_sample2() {
    
    // Get a queue backed by a GPU for running our squaring kernel.
    dispatch_queue_t queue =
    gcl_create_dispatch_queue(CL_DEVICE_TYPE_GPU, NULL);
    
    // Did we get a GPU?  If not, fall back to the CPU device.
    if (queue == NULL) {
        gcl_create_dispatch_queue(CL_DEVICE_TYPE_GPU, NULL);
    }
    
    // In any case, print out the device you're using:
    
    fprintf(stdout, "\nExamining workgroup info for square_kernel on device ");
    print_device_info(gcl_get_device_id_with_dispatch_queue(queue));
    
    // Now find out what OpenCL thinks is the best workgroup size for
    // executing this kernel on this particular device.  Notice that this
    // method is executed in a block, on a dispatch queue you've created
    // with OpenCL.
    
    dispatch_sync(queue,
                  ^{
                      size_t wgs, preferred_wgs_multiple;
                      cl_ulong local_memsize, private_memsize;
                      
                      // The next two calls give you information about how much
                      // memory, local and private, is used by the kernel on this
                      // particular device.
                      gcl_get_kernel_block_workgroup_info(square_kernel,
                                                          CL_KERNEL_LOCAL_MEM_SIZE,
                                                          sizeof(local_memsize),
                                                          &local_memsize, NULL);
                      fprintf(stdout, "Local memory size: %lld\n", local_memsize);
                      
                      gcl_get_kernel_block_workgroup_info(square_kernel,
                                                          CL_KERNEL_PRIVATE_MEM_SIZE,
                                                          sizeof(private_memsize),
                                                          &private_memsize, NULL);
                      fprintf(stdout,
                              "Private memory size: %lld\n", private_memsize);
                      
                      // Ask OpenCL to suggest the optimal workgroup
                      // size for this kernel on this device.
                      gcl_get_kernel_block_workgroup_info(square_kernel,
                                                          CL_KERNEL_WORK_GROUP_SIZE,
                                                          sizeof(wgs), &wgs, NULL);
                      fprintf(stdout, "Workgroup size: %ld\n", wgs);
                      
                      // Finally, you can ask OpenCL for a workgroup size multiple.
                      // This is a performance hint.
                      gcl_get_kernel_block_workgroup_info(square_kernel,
                                                          CL_KERNEL_PREFERRED_WORK_GROUP_SIZE_MULTIPLE,
                                                          sizeof(preferred_wgs_multiple),
                                                          &preferred_wgs_multiple, NULL);
                      fprintf(stdout, "Preferred workgroup size multiple: %ld\n",
                              preferred_wgs_multiple);
                      
                      // You can now use these workgroup values to craft an
                      // appropriate cl_ndrange structure for use in launching
                      // your kernel.
                      
                  });
    
    dispatch_release(queue);
}

int main (int argc, const char * argv[])
{
    mainCLNetwork(argc, argv);
    exit(0);

    runThreads();
    printf("\nHW1\n");
    hello_world_sample1();
    printf("\nHW2\n");
    hello_world_sample2();

    printf("\nImage\n");
    mainImages(argc, argv);

    printf("\nBuffer\n");
    mainBufferTest(argc, argv);
    
    exit(0);
    
    printf("\n\nExec\n\n");
    
    int i;
    char name[128];
    
    // First, try to obtain a dispatch queue that can send work to the
    // GPU in our system.                                             // 2
    dispatch_queue_t queue = gcl_create_dispatch_queue(CL_DEVICE_TYPE_GPU, NULL);
    
    // In the event that our system does NOT have an OpenCL-compatible GPU,
    // we can use the OpenCL CPU compute device instead.
    if (queue == NULL) {
        queue = gcl_create_dispatch_queue(CL_DEVICE_TYPE_CPU, NULL);
    }
    
    // This is not required, but let's print out the name of the device
    // we are using to do work.  We could use the same function,
    // clGetDeviceInfo, to obtain all manner of information about the device.
    cl_device_id gpu = gcl_get_device_id_with_dispatch_queue(queue);
    clGetDeviceInfo(gpu, CL_DEVICE_NAME, 128, name, NULL);
    fprintf(stdout, "Created a dispatch queue using the %s\n", name);
    
    // Here we hardcode some test data.
    // Normally, when this application is running for real, data would come from
    // some REAL source, such as a camera, a sensor, or some compiled collection
    // of statistics—it just depends on the problem you want to solve.
    float *test_in = (float *)malloc(sizeof(cl_float) * NUM_VALUES);
    
    for (i = 0; i < NUM_VALUES; i++) {
        test_in[i] = (cl_float)i;
    }
    
    // Once the computation using CL is done, will have to read the results
    // back into our application's memory space.  Allocate some space for that.
    float *test_out = (float *)malloc(sizeof(cl_float) * NUM_VALUES);
    
    // The test kernel takes two parameters: an input float array and an
    // output float array.  We can't send the application's buffers above, since
    // our CL device operates on its own memory space.  Therefore, we allocate
    // OpenCL memory for doing the work.  Notice that for the input array,
    // we specify CL_MEM_COPY_HOST_PTR and provide the fake input data we
    // created above.  This tells OpenCL to copy the data into its memory
    // space before it executes the kernel.                               // 3
    void *mem_in  = gcl_malloc(sizeof(cl_float) * NUM_VALUES, test_in,
                               CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR);
    
    // The output array is not initalized; we're going to fill it up when
    // we execute our kernel.                                             // 4
    void *mem_out = gcl_malloc(sizeof(cl_float) * NUM_VALUES, NULL, CL_MEM_WRITE_ONLY);
    
    // Dispatch the kernel block using one of the dispatch_ commands and the
    // queue created earlier.                                            // 5
    dispatch_sync(queue, ^{
        // Although we could pass NULL as the workgroup size, which would tell
        // OpenCL to pick the one it thinks is best, we can also ask
        // OpenCL for the suggested size, and pass it ourselves.
        size_t wgs;
        gcl_get_kernel_block_workgroup_info(square_kernel,
                                            CL_KERNEL_WORK_GROUP_SIZE,
                                            sizeof(wgs), &wgs, NULL);
        
        // The N-Dimensional Range over which we'd like to execute our
        // kernel.  In this case, we're operating on a 1D buffer, so
        // it makes sense that the range is 1D.
        cl_ndrange range = {                                              // 6
            1,                     // The number of dimensions to use.
            {0, 0, 0},             // The offset in each dimension.  To specify
            // that all the data is processed, this is 0
            // in the test case.                   // 7
            {NUM_VALUES, 0, 0},    // The global range—this is how many items
            // IN TOTAL in each dimension you want to
            // process.
            {wgs, 0, 0}            // The local size of each workgroup.  This
            // determines the number of work items per
            // workgroup.  It indirectly affects the
            // number of workgroups, since the global
            // size / local size yields the number of
            // workgroups.  In this test case, there are
            // NUM_VALUE / wgs workgroups.
        };
        
        // Calling the kernel is easy; simply call it like a function,
        // passing the ndrange as the first parameter, followed by the expected
        // kernel parameters.  Note that we case the 'void*' here to the
        // expected OpenCL types.  Remember, a 'float' in the
        // kernel, is a 'cl_float' from the application's perspective.   // 8
        square_kernel(&range, (cl_float *)mem_in, (cl_float *)mem_out);
        
        // Getting data out of the device's memory space is also easy;
        // use gcl_memcpy.  In this case, gcl_memcpy takes the output
        // computed by the kernel and copies it over to the
        // application's memory space.                                   // 9
        gcl_memcpy(test_out, mem_out, sizeof(cl_float) * NUM_VALUES);
    });
    
    // Check to see if the kernel did what it was supposed to:
    if (validate(test_in, test_out)) {
        fprintf(stdout, "All values were properly squared.\n");
    }
    
    // Don't forget to free up the CL device's memory when you're done. // 10
    gcl_free(mem_in);
    gcl_free(mem_out);
    
    // And the same goes for system memory, as usual.
    free(test_in);
    free(test_out);
    
    // Finally, release your queue just as you would any GCD queue.    // 11
    dispatch_release(queue);
}

